# -*- coding: utf-8 -*-
#
# Copyright 2021 Simon Bertrand
#
# This file is part of ClusterCharacteristics.
#
# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; either version 2 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program; if not, see <http://www.gnu.org/licenses/>.

from ClustersFeatures import settings
from ClustersFeatures import raising_errors


from .version import __version__
from .index_core import __IndexCore

import pandas as pd
import numpy as np
from scipy import spatial
from sklearn.metrics import silhouette_samples

from ClustersFeatures.src._data import __Data
from ClustersFeatures.src._score import __Score
from ClustersFeatures.src._score_index import __ScoreIndex
from ClustersFeatures.src._info import __Info
from ClustersFeatures.src._graph import __Graph
from ClustersFeatures.src._utils import __Utils
from ClustersFeatures.src._density import __Density
from ClustersFeatures.src._confusion_hypersphere import __ConfusionHypersphere
from ClustersFeatures.src._verify import __Verify


from ClustersFeatures.imputation import __Imputation

class ClustersCharacteristics(__Score,__Data,__ScoreIndex,__Info,__ConfusionHypersphere,__Verify,__Graph,__Utils,__IndexCore, __Density,__Imputation):
    """Class Author: BERTRAND Simon - simonbertrand.contact@gmail.com

    Made for preparing the summer mission with iCube, Strasbourg (D-IR on FoDoMust).
    This class has been made in order to facilitate the manipulation of Clusters generated by unsupervised techniques.
    It computes many scores and indexes to evaluate the generated clusters. Some utils tools such as data visualisation are also implemented.

    :param pd.DataFrame pd_df: Dataframe to analyse concatenated with the target vector
    :param str target: The name of the column target of pd_df dataframe

    :returns: ClustersCharacteristics Instance

    >>> CC=ClustersCharacteristics(pd_df,"target")

    Many features are available as instance variables, here is the list:

    :VAR self.num_clusters: Returns the number of clusters
    :VAR self.num_observations: Returns the number of observations (pd_df.shape[0])
    :VAR self.num_observation_for_specific_cluster: Returns a dict with cluster as key and number of observations as value
    :VAR self.data_dimension: Returns the number of features/directions/dimensions (pd_df.shape[1]-1)
    :VAR self.labels_clusters: Returns a list of all clusters labels
    :VAR self.label_target: Returns the given argument "target" used in the initialisation of ClustersCharacteristics instance
    :VAR self.data_clusters: Returns a dict with label cluster as key and sub-dataframe with same label cluster target as value
    :VAR self.data_centroids: Returns a dict with label cluster as key and centroid point Series as value
    :VAR self.data_barycenter: Returns a Series of the dataframe barycenter
    :VAR self.data_radiuscentroid: Returns a dict with ["max":,"75p","median","mean","min"] as keys and a dict with clusters as keys and centroid radius as value
    :VAR self.data_target: Returns the vector target
    :VAR self.data_frame: Returns the dataframe without the target vector
    :VAR self.data_features: Returns the dataframe with the target vector (pd_df)
    :VAR self.data_every_element_distance_to_every_element: Returns pairwise elements distances (Generated by Scipy)
    :VAR self.data_every_element_distance_to_centroids: Returns each distance between element of the dataset and each centroid
    :VAR self.data_every_possible_cluster_pairs: Returns all the possible clusters pairs of elements
    :VAR self.data_every_cluster_element_distance_to_centroids: Returns the distance between element belonging a cluster and its centroid for each cluster

    For example :

    >>> CC.num_clusters
    """

    def __init__(self, pd_df_, label_target,**args):
        """Initialisation of the ClusterCharacteristics instance
        :param pd.DataFrame pd_df: Dataframe to analyse concatenated with the target vector
        :param str target: The name of the column target of pd_df dataframe
        """
        raising_errors.verify_pandas_df_and_not_empty(pd_df_)
        raising_errors.verify_no_object_columns_and_delete_it(pd_df_)
        raising_errors.verify_pandas_df_and_not_empty(pd_df_)


        #Imputation if NaN values are detected
        if pd_df_.isnull().sum().sum() != 0:
            try:
                estimator=args['imputation_estimator']
                pd_df=self._imputation_detect_nan(pd_df_, estimator)
                print("test1")
            except KeyError:
                pd_df=self._imputation_detect_nan(pd_df_, False).copy()
                print("test2")
        else:
            pd_df=pd_df_.copy()


        #Used to memory every index
        self._listcode_index_compute = []
        self.details_index_compute = {el: {el2: {} for el2 in list(self.IndexCore_get_all_index()[el].keys())} for el in
                                      list(self.IndexCore_get_all_index().keys())}

        self.num_clusters = np.nan
        self.num_observations = np.nan
        self.num_observation_for_specific_cluster = {}
        self.data_dimension = np.nan
        self.labels_clusters = np.nan
        self.data_clusters = {}
        self.data_centroids = {}
        self.data_barycenter = pd.DataFrame()
        self.data_radiuscentroid = {"max": {}, "75p": {}, "median": {}, "mean": {}, "min": {}}
        self.label_target = label_target
        self.data_target = pd.DataFrame()
        self.data_frame = pd.DataFrame()
        self.data_features = pd.DataFrame()
        self.data_confusion_hypersphere = pd.DataFrame()
        self.data_every_element_distance_to_centroids = pd.DataFrame()

        if (self.label_target in pd_df.columns):
            # Save the dataframe
            self.data_frame = pd_df.copy()
            self.data_features = pd_df.copy()
            self.data_target = self.data_features.pop(label_target)

            self.data_dimension = self.data_features.shape[1]

            # Search for unique cluster's name/value and save the number of element of each cluster
            self.labels_clusters = np.unique(self.data_target)
            self.num_clusters = len(self.labels_clusters)

            # Compute the barycenter
            self.data_barycenter = self.data_features.mean()

            # Calcul the silhouette coefficient for each sample and save it
            self.score_index_silhouette_matrix = pd.DataFrame(index=self.data_features.index.values,
                                                              data=silhouette_samples(self.data_features,
                                                                                      self.data_target),
                                                              columns=['Silhouette Score'])
            self.score_index_silhouette_matrix['Cluster'] = self.data_target

            # Compute each centroid with groupby pandas function
            self.data_centroids = self.data_frame.groupby(by=label_target).mean().T

            # Prepare the compute of the distance between every element and every centroid and then compute it with all elements
            self.data_every_element_distance_to_centroids = pd.DataFrame(index=self.data_frame.index.values)
            self.data_every_element_distance_to_every_element = pd.DataFrame(spatial.distance_matrix(self.data_features,
                                                                                        self.data_features), index=self.data_frame.index.values, columns=self.data_frame.index.values)

            self.data_every_cluster_element_distance_to_centroids = {}
            for Cluster in self.labels_clusters:
                # Save each cluster separately
                self.data_clusters[Cluster] = self.data_frame[self.data_frame[label_target] == Cluster].drop(
                    columns=label_target)

                # Calcul each distance between element of one cluster and its centroid
                # Compute the same thing for the whole dataset. We compute it right now to avoid future useless calculs
                self.data_every_element_distance_to_centroids[Cluster] = np.sqrt(np.sum((self.data_features.values -
                                                                                         self.data_features.shape[0] * [
                                                                                             self.data_centroids[
                                                                                                 Cluster].values]) ** 2,
                                                                                        axis=1))

                self.data_every_cluster_element_distance_to_centroids[Cluster] = \
                self.data_every_element_distance_to_centroids[Cluster].iloc[self.data_clusters[Cluster].index]

                # Save the different default centroid's radius options
                self.data_radiuscentroid['max'][Cluster] = np.round(
                    np.max(self.data_every_cluster_element_distance_to_centroids[Cluster]), settings.precision)
                self.data_radiuscentroid['mean'][Cluster] = np.round(
                    np.mean(self.data_every_cluster_element_distance_to_centroids[Cluster]), settings.precision)
                self.data_radiuscentroid['75p'][Cluster] = np.round(
                    np.percentile(self.data_every_cluster_element_distance_to_centroids[Cluster], 75), settings.precision)
                self.data_radiuscentroid['median'][Cluster] = np.round(
                    np.median(self.data_every_cluster_element_distance_to_centroids[Cluster]), settings.precision)
                self.data_radiuscentroid['min'][Cluster] = np.min(
                    self.data_every_cluster_element_distance_to_centroids[Cluster])

            self.num_observations = len(self.data_features)
            self.num_observation_for_specific_cluster = {Cluster: len(self.data_clusters[Cluster]) for Cluster in
                                                         self.labels_clusters}

            # Save a list for itering all possible cluster pairs
            self.data_every_possible_cluster_pairs = np.array(
                [(Cluster1, Cluster2) for i, Cluster1 in enumerate(self.labels_clusters) for Cluster2 in
                 self.labels_clusters[i + 1:]])




        else:
            raising_errors.wrong_label_target(label_target)

        """Initialisation and saving of matrixs that need to be computed many times 
        It optimizes for example the GDI and Dunn Indexes
        """
        #defining data_interelement_distance_MAXIMUM/MINIMUM_matrix:
        self.data_interelement_distance_minimum_matrix=pd.DataFrame(np.zeros((self.num_clusters, self.num_clusters)), index=self.labels_clusters,
                              columns=self.labels_clusters)
        self.data_interelement_distance_maximum_matrix = self.data_interelement_distance_minimum_matrix.copy()
        # Putting the diag to nan to avoid min/max issues
        self.data_interelement_distance_minimum_matrix[np.eye(self.num_clusters) > 0] = np.nan
        self.data_interelement_distance_maximum_matrix[np.eye(self.num_clusters) > 0] = np.nan
        #Computing all min/max values
        for Cluster1, Cluster2 in self.data_every_possible_cluster_pairs:
            self.data_interelement_distance_minimum_matrix.loc[Cluster1, Cluster2] = self.data_interelement_distance_between_elements_of_two_clusters(
                Cluster1, Cluster2).min().min()
            self.data_interelement_distance_maximum_matrix.loc[Cluster1, Cluster2] = self.data_interelement_distance_between_elements_of_two_clusters(
                Cluster1, Cluster2).max().max()
        #Using symetric matrixs properties to return the final dataframe
        self.data_interelement_distance_minimum_matrix = self.data_interelement_distance_minimum_matrix + self.data_interelement_distance_minimum_matrix.T
        self.data_interelement_distance_maximum_matrix = self.data_interelement_distance_maximum_matrix + self.data_interelement_distance_maximum_matrix.T


