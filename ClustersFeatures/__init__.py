# -*- coding: utf-8 -*-
#
# Copyright 2021 Simon Bertrand
#
# This file is part of ClusterCharacteristics.
#
# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; either version 2 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program; if not, see <http://www.gnu.org/licenses/>.

from ClustersFeatures import settings
from ClustersFeatures import raising_errors

from .version import __version__

import pandas as pd
import numpy as np
from scipy import spatial

from sklearn.metrics import silhouette_samples

from ClustersFeatures.src._data import Data
from ClustersFeatures.src._score import Score
from ClustersFeatures.src._score_index import ScoreIndex
from ClustersFeatures.src._info import Info
from ClustersFeatures.src._graph import Graph
from ClustersFeatures.src._utils import Utils
from ClustersFeatures.src._confusion_hypersphere import ConfusionHypersphere
from ClustersFeatures.src._verify import Verify

class ClustersCharacteristics(Score,Data,ScoreIndex,Info,ConfusionHypersphere,Verify,Graph,Utils):
    """
    Class Author: BERTRAND Simon - simonbertrand.contact@gmail.com
    Made for preparing the summer mission with iCube, Strasbourg (D-IR on FoDoMust)
    This class has been made in order to facilitate the manipulation of Clusters generated by unsupervised techniques
    It computes many scores and indexes to evaluate the generated clusters. Some utils tools such as data visualisation are also implemented
    """
    def __init__(self, pd_df, label_target):
        raising_errors.verify_pandas_df_and_not_empty(pd_df)


        self.num_clusters = np.nan
        self.num_observations = np.nan
        self.num_observation_for_specific_cluster = {}
        self.data_dimension = np.nan
        self.labels_clusters = np.nan
        self.data_clusters = {}
        self.data_centroids = {}
        self.data_barycenter = pd.DataFrame()
        self.data_radiuscentroid = {"max": {}, "75p": {}, "median": {}, "mean": {}, "min": {}}
        self.label_target = label_target
        self.data_target = pd.DataFrame()
        self.data_frame = pd.DataFrame()
        self.data_features = pd.DataFrame()
        self.data_confusion_hypersphere = pd.DataFrame()
        self.data_every_element_distance_to_centroids = pd.DataFrame()

        if (self.label_target in pd_df.columns):
            # Save the dataframe
            self.data_frame = pd_df.copy()
            self.data_features = pd_df.copy()
            self.data_target = self.data_features.pop(label_target)

            self.data_dimension = self.data_features.shape[1]

            # Search for unique cluster's name/value and save the number of element of each cluster
            self.labels_clusters = np.unique(self.data_target)
            self.num_clusters = len(self.labels_clusters)

            # Compute the barycenter
            self.data_barycenter = self.data_features.mean()

            # Calcul the silhouette coefficient for each sample and save it
            self.score_index_silhouette_matrix = pd.DataFrame(index=self.data_features.index.values,
                                                              data=silhouette_samples(self.data_features,
                                                                                      self.data_target),
                                                              columns=['Silhouette Score'])
            self.score_index_silhouette_matrix['Cluster'] = self.data_target

            # Compute each centroid with groupby pandas function
            self.data_centroids = self.data_frame.groupby(by=label_target).mean().T

            # Prepare the compute of the distance between every element and every centroid and then compute it with all elements
            self.data_every_element_distance_to_centroids = pd.DataFrame(index=self.data_frame.index.values)
            self.data_every_element_distance_to_every_element = pd.DataFrame(spatial.distance_matrix(self.data_features,
                                                                                        self.data_features), index=self.data_frame.index.values, columns=self.data_frame.index.values)

            self.data_every_cluster_element_distance_to_centroids = {}
            for Cluster in self.labels_clusters:
                # Save each cluster separately
                self.data_clusters[Cluster] = self.data_frame[self.data_frame[label_target] == Cluster].drop(
                    columns=label_target)

                # Calcul each distance between element of one cluster and its centroid
                # Compute the same thing for the whole dataset. We compute it right now to avoid future useless calculs
                self.data_every_element_distance_to_centroids[Cluster] = np.sqrt(np.sum((self.data_features.values -
                                                                                         self.data_features.shape[0] * [
                                                                                             self.data_centroids[
                                                                                                 Cluster].values]) ** 2,
                                                                                        axis=1))
                self.data_every_cluster_element_distance_to_centroids[Cluster] = \
                self.data_every_element_distance_to_centroids[Cluster].iloc[self.data_clusters[Cluster].index]

                # Save the different default centroid's radius options
                self.data_radiuscentroid['max'][Cluster] = np.round(
                    np.max(self.data_every_cluster_element_distance_to_centroids[Cluster]), settings.precision)
                self.data_radiuscentroid['mean'][Cluster] = np.round(
                    np.mean(self.data_every_cluster_element_distance_to_centroids[Cluster]), settings.precision)
                self.data_radiuscentroid['75p'][Cluster] = np.round(
                    np.percentile(self.data_every_cluster_element_distance_to_centroids[Cluster], 75), settings.precision)
                self.data_radiuscentroid['median'][Cluster] = np.round(
                    np.median(self.data_every_cluster_element_distance_to_centroids[Cluster]), settings.precision)
                self.data_radiuscentroid['min'][Cluster] = np.min(
                    self.data_every_cluster_element_distance_to_centroids[Cluster])

            self.num_observations = len(self.data_features)
            self.num_observation_for_specific_cluster = {Cluster: len(self.data_clusters[Cluster]) for Cluster in
                                                         self.labels_clusters}
            # Save a list for itering all possible cluster pairs
            self.data_every_possible_cluster_pairs = np.array(
                [(Cluster1, Cluster2) for i, Cluster1 in enumerate(self.labels_clusters) for Cluster2 in
                 self.labels_clusters[i + 1:]])

        else:
            raising_errors.wrong_label_target(label_target)


